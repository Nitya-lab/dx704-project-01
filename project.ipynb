{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDELa7o5UXrY"
      },
      "source": [
        "# DX 704 Week 1 Project\n",
        "\n",
        "This week's project will build a portfolio risk and return model, and make investing recommendations for hypothetical clients.\n",
        "You will collect historical data, estimate returns and risks, construct efficient frontier portfolios, and sanity check the certainty of the maximum return portfolio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6SxppNu8p8k"
      },
      "source": [
        "The full project description and a template notebook are available on GitHub at the following link.\n",
        "\n",
        "https://github.com/bu-cds-dx704/dx704-project-01\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmIaQcdCwObV"
      },
      "source": [
        "Feel free to use optimization tools or libraries (such as CVXOPT or scipy.optimize) to perform any calculations required for this mini project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Code\n",
        "\n",
        "You may find it helpful to refer to these GitHub repositories of Jupyter notebooks for example code.\n",
        "\n",
        "* https://github.com/bu-cds-omds/dx601-examples\n",
        "* https://github.com/bu-cds-omds/dx602-examples\n",
        "* https://github.com/bu-cds-omds/dx603-examples\n",
        "* https://github.com/bu-cds-omds/dx704-examples\n",
        "\n",
        "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pv3PslO0V5Lm"
      },
      "source": [
        "## Part 1: Collect Data\n",
        "\n",
        "Collect historical monthly price data for the last 24 months covering 6 different stocks.\n",
        "The data should cover 24 consecutive months including the last month that ended before this week's material was released on Blackboard.\n",
        "To be clear, if a month ends between the Blackboard release and submitting your project, you do not need to add that month.\n",
        "\n",
        "The six different stocks must include AAPL, SPY and TSLA.\n",
        "At least one of the remaining 3 tickers must start with the same letter as your last name (e.g. professor Considine could use COIN).\n",
        "This is to encourage diversity in what stocks you analyze; if you discuss this project with classmates, please make sure that you pick different tickers to differentiate your work.\n",
        "Do not pick stocks with fewer than 24 consecutive months of price data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas-market-calendars\n",
            "  Downloading pandas_market_calendars-5.1.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.2.65-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: pandas>=1.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas-market-calendars) (2.3.1)\n",
            "Requirement already satisfied: tzdata in /home/codespace/.local/lib/python3.12/site-packages (from pandas-market-calendars) (2025.2)\n",
            "Requirement already satisfied: python-dateutil in /home/codespace/.local/lib/python3.12/site-packages (from pandas-market-calendars) (2.9.0.post0)\n",
            "Collecting exchange-calendars>=3.3 (from pandas-market-calendars)\n",
            "  Downloading exchange_calendars-4.11.1-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2.3.1)\n",
            "Requirement already satisfied: requests>=2.31 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2.32.4)\n",
            "Collecting multitasking>=0.0.7 (from yfinance)\n",
            "  Downloading multitasking-0.0.12.tar.gz (19 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.3.8)\n",
            "Requirement already satisfied: pytz>=2022.5 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (2025.2)\n",
            "Collecting frozendict>=2.3.4 (from yfinance)\n",
            "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
            "Collecting peewee>=3.16.2 (from yfinance)\n",
            "  Downloading peewee-3.18.2.tar.gz (949 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.2/949.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /home/codespace/.local/lib/python3.12/site-packages (from yfinance) (4.13.4)\n",
            "Collecting curl_cffi>=0.7 (from yfinance)\n",
            "  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting protobuf>=3.19.0 (from yfinance)\n",
            "  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting websockets>=13.0 (from yfinance)\n",
            "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (4.14.1)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.7.9)\n",
            "Requirement already satisfied: pycparser in /home/codespace/.local/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.22)\n",
            "Collecting pyluach (from exchange-calendars>=3.3->pandas-market-calendars)\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting toolz (from exchange-calendars>=3.3->pandas-market-calendars)\n",
            "  Downloading toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting korean_lunar_calendar (from exchange-calendars>=3.3->pandas-market-calendars)\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil->pandas-market-calendars) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Downloading pandas_market_calendars-5.1.1-py3-none-any.whl (127 kB)\n",
            "Downloading yfinance-0.2.65-py2.py3-none-any.whl (119 kB)\n",
            "Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading exchange_calendars-4.11.1-py3-none-any.whl (208 kB)\n",
            "Downloading frozendict-2.4.6-py312-none-any.whl (16 kB)\n",
            "Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n",
            "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
            "Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Building wheels for collected packages: multitasking, peewee\n",
            "  Building wheel for multitasking (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15636 sha256=fbb9e246db941c2017f3cf08ac91d482552d6fdbc43598c123e4fac4ea28d4db\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n",
            "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for peewee: filename=peewee-3.18.2-cp312-cp312-linux_x86_64.whl size=1049308 sha256=5a96b4236bf6a13c50b7b655d32827957aeaa6b958032764fc7b1782b49bff77\n",
            "  Stored in directory: /home/codespace/.cache/pip/wheels/d1/df/a9/0202b051c65b11c992dd6db9f2babdd2c44ec7d35d511be5d3\n",
            "Successfully built multitasking peewee\n",
            "Installing collected packages: peewee, multitasking, korean_lunar_calendar, websockets, toolz, pyluach, protobuf, frozendict, curl_cffi, yfinance, exchange-calendars, pandas-market-calendars\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [pandas-market-calendars]-market-calendars]\n",
            "\u001b[1A\u001b[2KSuccessfully installed curl_cffi-0.13.0 exchange-calendars-4.11.1 frozendict-2.4.6 korean_lunar_calendar-0.3.1 multitasking-0.0.12 pandas-market-calendars-5.1.1 peewee-3.18.2 protobuf-6.32.0 pyluach-2.2.0 toolz-1.0.0 websockets-15.0.1 yfinance-0.2.65\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: matplotlib in /home/codespace/.local/lib/python3.12/site-packages (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (4.58.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/codespace/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install pandas-market-calendars yfinance\n",
        "!python3 -m pip install matplotlib\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf                #yfinance as yf is used to download prices "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6pL-ppubxfvC"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "TICKERS = [\"AAPL\", \"SPY\", \"TSLA\", \"SBUX\", \"MSFT\", \"NVDA\"]  # includes 'S' for Sharma\n",
        "RELEASE_DATE = \"2025-09-01\"                                 # I have done 2025-09-01 \n",
        "N_MONTHS = 24                                                  # observations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1uH9oDQ1rEQT"
      },
      "source": [
        "Save the data as a TSV file named \"historical_prices.tsv\" and include a header row with the column names \"date\" and the 6 stock ticker symbols.\n",
        "The date should be the last trading day of the month, so it may not be the last day of the month.\n",
        "For example, the last trading day of November 2024 was 2024-11-29.\n",
        "The remaining columns should contain the adjusted closing prices of the corresponding stock tickers on that day.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  historical_prices.tsv\n",
            "      date       AAPL        SPY       TSLA      SBUX       MSFT      NVDA\n",
            "2023-09-29 169.549286 417.865631 250.220001 86.798462 311.062317 43.475826\n",
            "2023-10-31 169.113556 408.794342 200.839996 87.720947 333.090393 40.758278\n",
            "2023-11-30 188.355316 446.135223 240.080002 94.953987 374.042236 46.745083\n"
          ]
        }
      ],
      "source": [
        "#this code here is saying to compute a start date that is 24months plus 6 months which is like a cushion to ensure enough data\n",
        "start = (pd.to_datetime(RELEASE_DATE) - pd.DateOffset(months=N_MONTHS + 6)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "# here we tell yfinance to return adjusted prices in the close field \n",
        "raw = yf.download(TICKERS, start=start, end=RELEASE_DATE, auto_adjust=True, progress=False)\n",
        "\n",
        "#selects the closed block aka adjusted close \n",
        "close = raw[\"Close\"].copy()\n",
        "#ensured dates are sorted ascending \n",
        "close = close.sort_index()\n",
        "\n",
        "#gets the actual last trading day of ach month \n",
        "last_dates = close.groupby(close.index.to_period(\"M\")).apply(lambda df: df.index.max())\n",
        "monthly = close.loc[last_dates.to_list()]\n",
        "\n",
        "#keeps the last 24months and enforces column order \n",
        "monthly = monthly.tail(N_MONTHS)[TICKERS]\n",
        "\n",
        "#format and save \n",
        "monthly.index = monthly.index.strftime(\"%Y-%m-%d\")  # keep the real last-trading-day date\n",
        "monthly.index.name = \"date\"\n",
        "monthly.to_csv(\"historical_prices.tsv\", sep=\"\\t\", index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"historical_prices.tsv\", sep=\"\\t\")\n",
        "assert list(df.columns) == [\"date\"] + TICKERS, \"Header mismatch\"\n",
        "assert len(df) == N_MONTHS, f\"Expected {N_MONTHS} rows, got {len(df)}\"\n",
        "print(\"  historical_prices.tsv\")\n",
        "print(df.head(3).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hp0yuXPtT9V"
      },
      "source": [
        "Submit \"historical_prices.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XdNVWWirUd5"
      },
      "source": [
        "## Part 2: Calculate Historical Asset Returns\n",
        "\n",
        "Calculate the historical asset returns based on the price data that you previously collected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aL-kVua2xex-"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "INPUT_FILE = \"historical_prices.tsv\"\n",
        "OUTPUT_FILE = \"historical_returns.tsv\"\n",
        "\n",
        "#reading the part 1 output \n",
        "prices = pd.read_csv(INPUT_FILE, sep=\"\\t\")\n",
        "\n",
        "\n",
        "assert \"date\" in prices.columns, \"Missing 'date' column in historical_prices.tsv\"\n",
        "ticker_cols = [c for c in prices.columns if c != \"date\"]\n",
        "assert len(ticker_cols) == 6, f\"Expected 6 tickers, found {len(ticker_cols)}: {ticker_cols}\"\n",
        "\n",
        "prices[\"date\"] = pd.to_datetime(prices[\"date\"])\n",
        "prices = prices.sort_values(\"date\").reset_index(drop=True)\n",
        "numeric = prices[ticker_cols].astype(float)\n",
        "\n",
        "\n",
        "returns = numeric.pct_change().dropna(how=\"any\")         # drops the first (NaN) row\n",
        "returns.index = prices.loc[returns.index, \"date\"]         # align dates to month-ends at t\n",
        "returns.index.name = \"date\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjhEYCWOrIu3"
      },
      "source": [
        "Save the data as a TSV file named \"historical_returns.tsv\" and include a header row with the column names \"date\" and the 6 stock ticker symbols.\n",
        "Each row should have the date at the end of the month and the corresponding *relative* price changes.\n",
        "For example, if the previous price was \\$100 and the new price is \\$110, the return value should be 0.10.\n",
        "There should only be 23 rows of data in this file, since they are computed as the differences of 24 prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cN-7q9QvvyKG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  historical_returns.tsv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>SBUX</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>NVDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2023-10-31</td>\n",
              "      <td>-0.002570</td>\n",
              "      <td>-0.021709</td>\n",
              "      <td>-0.197346</td>\n",
              "      <td>0.010628</td>\n",
              "      <td>0.070816</td>\n",
              "      <td>-0.062507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2023-11-30</td>\n",
              "      <td>0.113780</td>\n",
              "      <td>0.091344</td>\n",
              "      <td>0.195379</td>\n",
              "      <td>0.082455</td>\n",
              "      <td>0.122945</td>\n",
              "      <td>0.146886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2023-12-29</td>\n",
              "      <td>0.013583</td>\n",
              "      <td>0.045655</td>\n",
              "      <td>0.034988</td>\n",
              "      <td>-0.033132</td>\n",
              "      <td>-0.007574</td>\n",
              "      <td>0.058934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date      AAPL       SPY      TSLA      SBUX      MSFT      NVDA\n",
              "0  2023-10-31 -0.002570 -0.021709 -0.197346  0.010628  0.070816 -0.062507\n",
              "1  2023-11-30  0.113780  0.091344  0.195379  0.082455  0.122945  0.146886\n",
              "2  2023-12-29  0.013583  0.045655  0.034988 -0.033132 -0.007574  0.058934"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>SPY</th>\n",
              "      <th>TSLA</th>\n",
              "      <th>SBUX</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>NVDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2025-06-30</td>\n",
              "      <td>0.021509</td>\n",
              "      <td>0.051386</td>\n",
              "      <td>-0.083126</td>\n",
              "      <td>0.091483</td>\n",
              "      <td>0.080481</td>\n",
              "      <td>0.169252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2025-07-31</td>\n",
              "      <td>0.011698</td>\n",
              "      <td>0.023032</td>\n",
              "      <td>-0.029560</td>\n",
              "      <td>-0.026956</td>\n",
              "      <td>0.072556</td>\n",
              "      <td>0.125831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2025-08-29</td>\n",
              "      <td>0.119639</td>\n",
              "      <td>0.020520</td>\n",
              "      <td>0.083044</td>\n",
              "      <td>-0.004353</td>\n",
              "      <td>-0.048692</td>\n",
              "      <td>-0.020746</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date      AAPL       SPY      TSLA      SBUX      MSFT      NVDA\n",
              "20  2025-06-30  0.021509  0.051386 -0.083126  0.091483  0.080481  0.169252\n",
              "21  2025-07-31  0.011698  0.023032 -0.029560 -0.026956  0.072556  0.125831\n",
              "22  2025-08-29  0.119639  0.020520  0.083044 -0.004353 -0.048692 -0.020746"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "out = returns.copy()\n",
        "out.index = out.index.strftime(\"%Y-%m-%d\")\n",
        "out.to_csv(OUTPUT_FILE, sep=\"\\t\", index=True)\n",
        "\n",
        "check = pd.read_csv(OUTPUT_FILE, sep=\"\\t\")\n",
        "assert list(check.columns) == [\"date\"] + ticker_cols, \"Header mismatch in historical_returns.tsv\"\n",
        "assert len(check) == 23, f\"Expected 23 rows of returns, found {len(check)}\"\n",
        "assert check.drop(columns=[\"date\"]).isna().sum().sum() == 0, \"Found NaNs in returns\"\n",
        "\n",
        "print(\"  historical_returns.tsv\")\n",
        "display(check.head(3))\n",
        "display(check.tail(3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyBtnCTUtfRq"
      },
      "source": [
        "Submit \"historical_returns.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoCkf4ouV9IA"
      },
      "source": [
        "## Part 3: Estimate Returns\n",
        "\n",
        "Estimate the expected returns for each asset using the previously calculated return data.\n",
        "Just compute the average (mean) return for each asset over your data set; do not use other estimators that have been mentioned.\n",
        "This will serve as your estimate of expected return for each asset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N2iDEhSRxd2n"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "INPUT_FILE = \"historical_returns.tsv\"\n",
        "OUTPUT_FILE = \"estimated_returns.tsv\"\n",
        "\n",
        "\n",
        "# Load returns\n",
        "rets = pd.read_csv(INPUT_FILE, sep=\"\\t\")\n",
        "assert \"date\" in rets.columns, \"Missing 'date' column in historical_returns.tsv\"\n",
        "tickers = [c for c in rets.columns if c != \"date\"]\n",
        "assert len(tickers) == 6, f\"Expected 6 tickers, found {len(tickers)}\"\n",
        "\n",
        "R = rets[tickers].astype(float)\n",
        "\n",
        "mu = R.mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5YTEwoarM2M"
      },
      "source": [
        "Save the estimated returns in a TSV file named \"estimated_returns.tsv\" and include a header row with the column names \"asset\" and \"estimated_return\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "At71YDpwvwUw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " estimated_returns.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "out = mu.reindex(tickers).reset_index()\n",
        "out.columns = [\"asset\", \"estimated_return\"]\n",
        "out.to_csv(OUTPUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "check = pd.read_csv(OUTPUT_FILE, sep=\"\\t\")\n",
        "assert list(check.columns) == [\"asset\", \"estimated_return\"]\n",
        "assert len(check) == 6\n",
        "assert check[\"estimated_return\"].isna().sum() == 0\n",
        "\n",
        "print(\" estimated_returns.tsv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjfnF-2Wtj6r"
      },
      "source": [
        "Submit \"estimated_returns.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTuIqrkAWXVL"
      },
      "source": [
        "## Part 4: Estimate Risk\n",
        "\n",
        "Estimate the covariance matrix for the asset returns to understand how the assets move together."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RFZfIkTMxcv7"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "INPUT = \"historical_returns.tsv\"\n",
        "OUTPUT = \"estimated_covariance.tsv\"\n",
        "\n",
        "\n",
        "rets = pd.read_csv(INPUT, sep=\"\\t\")\n",
        "assert \"date\" in rets.columns, \"Missing 'date' column in historical_returns.tsv\"\n",
        "tickers = [c for c in rets.columns if c != \"date\"]\n",
        "\n",
        "R = rets[tickers].astype(float)\n",
        "Sigma = R.cov()\n",
        "\n",
        "\n",
        "Sigma = Sigma.loc[tickers, tickers]\n",
        "Sigma.index.name = \"\"               # makes the first header cell blank\n",
        "Sigma.to_csv(OUTPUT, sep=\"\\t\")      # in pandas matrix format \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOmn4s_yr5qn"
      },
      "source": [
        "Save the estimated covariances to a TSV file named \"estimated_covariance.tsv\".\n",
        "The header row should have a blank column name followed by the names of the assets.\n",
        "Each data row should start with the name of an asset for that row, and be followed by the individual covariances corresponding to that row and column's assets.\n",
        "(This is the format of pandas's `to_csv` method with `sep=\"\\t\"` when used on a covariance matrix as computed in the examples.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Te-NPQxSvuXm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  estimated_covariance.tsv\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "with open(OUTPUT, \"r\", encoding=\"utf-8\") as f:\n",
        "    header = f.readline().rstrip(\"\\n\").split(\"\\t\")\n",
        "assert header[0] == \"\" and header[1:] == tickers, \"Header format not as required\"\n",
        "chk = pd.read_csv(OUTPUT, sep=\"\\t\", index_col=0)\n",
        "assert list(chk.columns) == tickers and list(chk.index) == tickers and chk.shape == (6, 6)\n",
        "\n",
        "print(\"  estimated_covariance.tsv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS9vek0btoK6"
      },
      "source": [
        "Submit \"estimated_covariance.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8rC5Eo3sEme"
      },
      "source": [
        "## Part 5: Construct the Maximum Return Portfolio\n",
        "\n",
        "Compute the maximum return portfolio based on your previously estimated risks and returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8LW0KKm-xb2I"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "INPUT = \"estimated_returns.tsv\"\n",
        "OUTPUT = \"maximum_return.tsv\"\n",
        "\n",
        "er = pd.read_csv(INPUT, sep=\"\\t\")\n",
        "assert list(er.columns) == [\"asset\", \"estimated_return\"], \"estimated_returns.tsv header must be ['asset','estimated_return']\"\n",
        "assert len(er) == 6, \"Expected 6 assets\"\n",
        "\n",
        "imax = er[\"estimated_return\"].idxmax()\n",
        "assets = er[\"asset\"].tolist()\n",
        "\n",
        "alloc = np.zeros(len(assets), dtype=float)\n",
        "alloc[imax] = 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjPOxui5sLTD"
      },
      "source": [
        "Save the maximum return portfolio in a TSV file named \"maximum_return.tsv\".\n",
        "The header row should have two columns, \"asset\" and \"allocation\".\n",
        "The allocation values should sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xLl_j8z1vtiT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " maximum_return.tsv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset</th>\n",
              "      <th>allocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SPY</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SBUX</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  asset  allocation\n",
              "0  AAPL         0.0\n",
              "1   SPY         0.0\n",
              "2  TSLA         0.0\n",
              "3  SBUX         0.0\n",
              "4  MSFT         0.0\n",
              "5  NVDA         1.0"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "out = pd.DataFrame({\"asset\": assets, \"allocation\": alloc})\n",
        "out.to_csv(OUTPUT, sep=\"\\t\", index=False)\n",
        "\n",
        "check = pd.read_csv(OUTPUT, sep=\"\\t\")\n",
        "assert list(check.columns) == [\"asset\", \"allocation\"]\n",
        "assert abs(check[\"allocation\"].sum() - 1.0) < 1e-9\n",
        "assert (check[\"allocation\"] >= 0).all()\n",
        "print(\" maximum_return.tsv\")\n",
        "check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bm3xrxptqJ2"
      },
      "source": [
        "Submit \"maximum_return.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_QxQ5NpsL-c"
      },
      "source": [
        "## Part 6: Construct the Minimum Risk Portfolio\n",
        "\n",
        "Compute the minimum risk portfolio based on your previously estimated risks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "daHSqhv9xbIF"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "INPUT = \"estimated_covariance.tsv\"\n",
        "OUTPUT = \"minimum_risk.tsv\"\n",
        "\n",
        "Sigma_df = pd.read_csv(INPUT, sep=\"\\t\", index_col=0)\n",
        "tickers = list(Sigma_df.columns)\n",
        "Sigma = Sigma_df.loc[tickers, tickers].to_numpy(dtype=float)\n",
        "n = len(tickers)\n",
        "\n",
        "def var_objective(w, Sigma=Sigma):\n",
        "    return float(w @ Sigma @ w)\n",
        "\n",
        "cons = ({\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0},)\n",
        "bounds = [(0.0, 1.0)] * n\n",
        "x0 = np.full(n, 1.0 / n)\n",
        "\n",
        "res = minimize(var_objective, x0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
        "if not res.success:\n",
        "    raise RuntimeError(\"Min-variance optimization failed: \" + res.message)\n",
        "\n",
        "w = res.x\n",
        "\n",
        "w[w < 0] = 0.0\n",
        "s = w.sum()\n",
        "if s <= 0:\n",
        "    raise ValueError(\"Degenerate solution: sum of weights <= 0\")\n",
        "w = w / s\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzldkIPxsQor"
      },
      "source": [
        "Save the minimum risk portfolio in a TSV file named \"minimum_risk.tsv\".\n",
        "The header row should have two columns, \"asset\" and \"allocation\".\n",
        "The allocation values should sum up to one.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YRXccAflvrBZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " minimum_risk.tsv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset</th>\n",
              "      <th>allocation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>3.396998e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SPY</td>\n",
              "      <td>3.663415e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>1.785062e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SBUX</td>\n",
              "      <td>6.290436e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>2.310543e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>6.107303e-18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  asset    allocation\n",
              "0  AAPL  3.396998e-01\n",
              "1   SPY  3.663415e-01\n",
              "2  TSLA  1.785062e-17\n",
              "3  SBUX  6.290436e-02\n",
              "4  MSFT  2.310543e-01\n",
              "5  NVDA  6.107303e-18"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "out = pd.DataFrame({\"asset\": tickers, \"allocation\": w})\n",
        "out.to_csv(OUTPUT, sep=\"\\t\", index=False)\n",
        "\n",
        "check = pd.read_csv(OUTPUT, sep=\"\\t\")\n",
        "assert list(check.columns) == [\"asset\", \"allocation\"]\n",
        "assert abs(check[\"allocation\"].sum() - 1.0) < 1e-8\n",
        "assert (check[\"allocation\"] >= -1e-10).all()  # allows tiny numerical noise\n",
        "\n",
        "print(\" minimum_risk.tsv\")\n",
        "check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5gy_XETtsoi"
      },
      "source": [
        "Submit \"minimum_risk.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzyJGWDvWhva"
      },
      "source": [
        "## Part 7: Build Efficient Frontier Portfolios\n",
        "\n",
        "Compute 101 portfolios along the mean-variance efficient frontier with evenly spaced estimated returns.\n",
        "The first portfolio should be the minimum risk portfolio from part 4, and the last portfolio should be the maximum return portfolio from part 3.\n",
        "The estimated return of each portfolio should be higher than the previous by one percent of the difference between the first and last portfolios.\n",
        "That is, the estimated return of the portfolios should be similar to `np.linspace(min_risk_return, max_return, 101)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XaR6mKwvxZ4W"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Inputs from previous parts\n",
        "ER_FILE   = \"estimated_returns.tsv\"\n",
        "COV_FILE  = \"estimated_covariance.tsv\"\n",
        "MIN_FILE  = \"minimum_risk.tsv\"\n",
        "MAX_FILE  = \"maximum_return.tsv\"\n",
        "OUT_FILE  = \"efficient_frontier.tsv\"\n",
        "\n",
        "# Loading inputs and align tickers consistently\n",
        "Sigma_df = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0)\n",
        "tickers = list(Sigma_df.columns)                     # canonical order\n",
        "Sigma = Sigma_df.loc[tickers, tickers].to_numpy(float)\n",
        "\n",
        "er = pd.read_csv(ER_FILE, sep=\"\\t\")\n",
        "mu_map = dict(zip(er[\"asset\"], er[\"estimated_return\"]))\n",
        "mu = np.array([mu_map[t] for t in tickers], dtype=float)\n",
        "\n",
        "w_min_df = pd.read_csv(MIN_FILE, sep=\"\\t\")\n",
        "w_min_map = dict(zip(w_min_df[\"asset\"], w_min_df[\"allocation\"]))\n",
        "w_min = np.array([w_min_map[t] for t in tickers], dtype=float)\n",
        "\n",
        "w_max_df = pd.read_csv(MAX_FILE, sep=\"\\t\")\n",
        "w_max_map = dict(zip(w_max_df[\"asset\"], w_max_df[\"allocation\"]))\n",
        "w_max = np.array([w_max_map[t] for t in tickers], dtype=float)\n",
        "\n",
        "# weights sum to 1 and are >=0\n",
        "assert abs(w_min.sum() - 1) < 1e-8 and (w_min >= -1e-12).all()\n",
        "assert abs(w_max.sum() - 1) < 1e-8 and (w_max >= -1e-12).all()\n",
        "\n",
        "# The Helper functions \n",
        "def port_stats(w, mu, Sigma):\n",
        "    r = float(w @ mu)\n",
        "    v = float(w @ Sigma @ w)\n",
        "    s = np.sqrt(v)\n",
        "    return r, v, s\n",
        "\n",
        "def solve_min_var_at_return(Sigma, mu, target, w0=None):\n",
        "    \"\"\"\n",
        "    Minimize w^T Σ w subject to:\n",
        "      1) sum(w) = 1\n",
        "      2) mu^T w = target\n",
        "      3) 0 <= w <= 1  (long-only)\n",
        "    \"\"\"\n",
        "    n = len(mu)\n",
        "    bounds = [(0.0, 1.0)] * n\n",
        "    cons = (\n",
        "        {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1.0},\n",
        "        {\"type\": \"eq\", \"fun\": lambda w, mu=mu, target=target: float(w @ mu) - target},\n",
        "    )\n",
        "    if w0 is None:\n",
        "        w0 = np.full(n, 1.0 / n)\n",
        "    res = minimize(lambda w: w @ Sigma @ w, w0, method=\"SLSQP\", bounds=bounds, constraints=cons)\n",
        "    return res\n",
        "\n",
        "# endpoint returns\n",
        "r_min, _, s_min = port_stats(w_min, mu, Sigma)\n",
        "r_max, _, s_max = port_stats(w_max, mu, Sigma)\n",
        "\n",
        "#  101 evenly spaced returns \n",
        "targets = np.linspace(r_min, r_max, 101)\n",
        "\n",
        "rows = []\n",
        "for i, tr in enumerate(targets):\n",
        "    if i == 0:\n",
        "        w = w_min.copy()\n",
        "    elif i == 100:\n",
        "        w = w_max.copy()\n",
        "    else:\n",
        "        # convex mix of endpoints, with alpha matching target return\n",
        "        alpha = (tr - r_min) / (r_max - r_min) if r_max > r_min else 0.0\n",
        "        w0 = (1 - alpha) * w_min + alpha * w_max\n",
        "        res = solve_min_var_at_return(Sigma, mu, tr, w0=w0)\n",
        "        if not res.success:\n",
        "            # Then Fallback to convex blend \n",
        "            w = np.clip(w0, 0, 1)\n",
        "            w = w / w.sum()\n",
        "        else:\n",
        "            w = res.x\n",
        "            # Clean tiny numerical noise and renormalize\n",
        "            w[w < 0] = 0.0\n",
        "            w = w / w.sum()\n",
        "\n",
        "    r, v, s = port_stats(w, mu, Sigma)\n",
        "    row = {\"index\": i, \"return\": r, \"risk\": s}\n",
        "    row.update({tickers[j]: w[j] for j in range(len(tickers))})\n",
        "    rows.append(row)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e3WwTJvsDzh"
      },
      "source": [
        "Save the portfolios in a TSV file named \"efficient_frontier.tsv\".\n",
        "The header row should have columns \"index\", \"return\", \"risk\", and all the asset tickers.\n",
        "Each data row should have the portfolio index (0-100), the estimated return of the portfolio, the estimated standard deviation (not variance) of the portfolio, and all the asset allocations (which should sum to one)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "e9DKadyNvniT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  efficient_frontier.tsv with 101 portfolios.\n"
          ]
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "frontier = pd.DataFrame(rows, columns=[\"index\", \"return\", \"risk\"] + tickers)\n",
        "frontier.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "chk = pd.read_csv(OUT_FILE, sep=\"\\t\")\n",
        "assert list(chk.columns) == [\"index\", \"return\", \"risk\"] + tickers\n",
        "assert len(chk) == 101\n",
        "assert np.allclose(chk.loc[0, tickers].to_numpy(float), w_min, atol=1e-6)   \n",
        "assert np.allclose(chk.loc[100, tickers].to_numpy(float), w_max, atol=1e-6) \n",
        "print(\"  efficient_frontier.tsv with 101 portfolios.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiOa06rItvbs"
      },
      "source": [
        "Submit \"efficient_frontier.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LoW0XBXAzzR6"
      },
      "source": [
        "## Part 8: Check Maximum Return Portfolio Stability\n",
        "\n",
        "Check the stability of the maximum return portfolio by resampling the estimated risk/return model.\n",
        "\n",
        "Repeat 1000 times -\n",
        "1. Use `np.random.multivariate_normal` to generate 23 return samples using your previously estimated risks and returns.\n",
        "2. Estimate the return of each asset using that resampled return history.\n",
        "3. Check which asset had the highest return in those resampled estimates.\n",
        "\n",
        "This procedure is a reduced and simplified version of the Michaud resampled efficient frontier procedure that takes uncertainty in the risk model into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Xfke5V57xYvT"
      },
      "outputs": [],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "ER_FILE   = \"estimated_returns.tsv\"\n",
        "COV_FILE  = \"estimated_covariance.tsv\"\n",
        "RETS_FILE = \"historical_returns.tsv\"\n",
        "OUT_FILE  = \"max_return_probabilities.tsv\"\n",
        "\n",
        "er = pd.read_csv(ER_FILE, sep=\"\\t\")                      # columns: asset, estimated_return\n",
        "Sigma_df = pd.read_csv(COV_FILE, sep=\"\\t\", index_col=0)  # covariance matrix\n",
        "rets = pd.read_csv(RETS_FILE, sep=\"\\t\")                  \n",
        "\n",
        "tickers = list(Sigma_df.columns)                         # canonical order\n",
        "mu_map = dict(zip(er[\"asset\"], er[\"estimated_return\"]))\n",
        "mu = np.array([mu_map[t] for t in tickers], dtype=float)\n",
        "Sigma = Sigma_df.loc[tickers, tickers].to_numpy(dtype=float)\n",
        "\n",
        "n_assets = len(tickers)\n",
        "n_samples = len(rets)    \n",
        "\n",
        "min_eig = np.linalg.eigvalsh((Sigma + Sigma.T) / 2).min()\n",
        "if min_eig < 0:\n",
        "    Sigma = Sigma + np.eye(n_assets) * (-(min_eig) + 1e-12)\n",
        "\n",
        "# Resampling loop \n",
        "rng = np.random.default_rng(42)\n",
        "counts = np.zeros(n_assets, dtype=int)\n",
        "num_trials = 1000\n",
        "\n",
        "for _ in range(num_trials):\n",
        "    samples = rng.multivariate_normal(mean=mu, cov=Sigma, size=n_samples, check_valid=\"ignore\")\n",
        "    mu_hat = samples.mean(axis=0)               \n",
        "    top_idx = int(np.argmax(mu_hat))            \n",
        "    counts[top_idx] += 1\n",
        "\n",
        "probs = counts / num_trials\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fes_ScDyz0jp"
      },
      "source": [
        "Save a file \"max_return_probabilities.tsv\" with the distribution of highest return assets.\n",
        "The header row should have columns \"asset\" and \"probability\".\n",
        "There should be a data row for each asset and its sample probability of having the highest return based on those 1000 resampled estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZAjr15ASvj1S"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  max_return_probabilities.tsv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>asset</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPL</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SPY</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TSLA</td>\n",
              "      <td>0.153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SBUX</td>\n",
              "      <td>0.006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MSFT</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NVDA</td>\n",
              "      <td>0.834</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  asset  probability\n",
              "0  AAPL        0.004\n",
              "1   SPY        0.001\n",
              "2  TSLA        0.153\n",
              "3  SBUX        0.006\n",
              "4  MSFT        0.002\n",
              "5  NVDA        0.834"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# YOUR CHANGES HERE\n",
        "\n",
        "out = pd.DataFrame({\"asset\": tickers, \"probability\": probs})\n",
        "out.to_csv(OUT_FILE, sep=\"\\t\", index=False)\n",
        "\n",
        "chk = pd.read_csv(OUT_FILE, sep=\"\\t\")\n",
        "assert list(chk.columns) == [\"asset\", \"probability\"]\n",
        "assert np.isclose(chk[\"probability\"].sum(), 1.0), \"Probabilities should sum to ~1\"\n",
        "print(\"  max_return_probabilities.tsv\")\n",
        "chk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xd34FQ6txoj"
      },
      "source": [
        "Submit \"max_return_probabilities.tsv\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYbJ21qUYvL_"
      },
      "source": [
        "## Part 9: Acknowledgments\n",
        "\n",
        "Make a file \"acknowledgments.txt\" documenting any outside sources or help on this project.\n",
        "If you discussed this assignment with anyone, please acknowledge them here.\n",
        "If you used any libraries not mentioned in this module's content, please list them with a brief explanation what you used them for.\n",
        "If you used any generative AI tools, please add links to your transcripts below, and any other information that you feel is necessary to comply with the generative AI policy.\n",
        "If no acknowledgements are appropriate, just write none in the file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exists: True\n"
          ]
        }
      ],
      "source": [
        "content = \"\"\"I acknowledge the use of the following libraries and resources:\n",
        "\n",
        "- pandas, numpy, matplotlib — data manipulation and plotting\n",
        "- yfinance — downloading market data\n",
        "- scipy.optimize — portfolio optimization\n",
        "\n",
        "I discussed this assignment with no one and did not use any additional sources beyond the course materials,\n",
        "other than occasional Google searches to help understand concepts covered in class. \n",
        "\"\"\"\n",
        "\n",
        "with open(\"acknowledgements.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(content)\n",
        "\n",
        "import os\n",
        "print(\"exists:\", os.path.exists(\"acknowledgements.txt\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I acknowledge the use of the following libraries and resources:\n",
        "\n",
        "- pandas, numpy, matplotlib — data manipulation and plotting\n",
        "- yfinance — downloading market data\n",
        "- scipy.optimize — portfolio optimization \n",
        "\n",
        "I discussed this assignment with no one and did not use any additional sources beyond the course materials other then google here and there to clarify materials learned in class to make sure I understand what im doing. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3oWYYHlt42V"
      },
      "source": [
        "Submit \"acknowledgements.txt\" in Gradescope."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8FWiTjvwscA"
      },
      "source": [
        "## Part 10: Code\n",
        "\n",
        "Please submit a Jupyter notebook that can reproduce all your calculations and recreate the previously submitted files.\n",
        "You do not need to provide code for data collection if you did that by manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDEYI-K8vcUW"
      },
      "source": [
        "Submit \"project.ipynb\" in Gradescope."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": false
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
